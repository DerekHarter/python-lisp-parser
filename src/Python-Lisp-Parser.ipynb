{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python Lisp Parser Working Notes\n",
      "--------------------------------\n",
      "\n",
      "Notebook to document work and tests setting up a simple Python Lisp Parser.\n",
      "\n",
      "First approach, break into subfunctions to handle parsing a list, and to handle gathering the operator and operands\n",
      "of a list.  This becomes recursive because the function gathering operands will call the list parsing function if\n",
      "it encounters an opening `(` indicating a new subexpression.\n",
      "\n",
      "Here we kind of use half-remembered compiler/parser ideas and language.  We use Python list to represent the resulting\n",
      "parse tree (as suggested).  Structure is a simple list of embedded lists mirroring the lisp structure.  We use the\n",
      "pop(0) on python lists to consume tokens, and we simply examine tokens[0] to peek at next token if we don't want to \n",
      "consume it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def tokenize(txt):\n",
      "    \"\"\"Tokenize a Lisp like program\n",
      "    \n",
      "    Break up a line of ascii text on tokens and return a list of the tokens.  This function\n",
      "    considers any sequence of whitespace and the ( and ) as the only valid delimeters between\n",
      "    tokens, which should be good enough for now.  We use Python re library to split up based on our\n",
      "    small list of delimiters.\n",
      "    \n",
      "    Parameters\n",
      "    -----------\n",
      "    txt : string\n",
      "        An ascii string of lisp text to be tokenized\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    tokens : list\n",
      "        A list of the recognized tokens in the text\n",
      "    \"\"\"\n",
      "    # split into tokens, use whitespace or the ( or ) character as delimeters\n",
      "    # the following usage of re.split also returns the delimiters that were matched\n",
      "    tokens = re.split('(\\s+|\\(|\\))', txt)\n",
      "    \n",
      "    # the previous re returns all delimiters, including string of whitespace and empty matches.\n",
      "    # we remove all empty or whitespace only matches, which leaves only valid tokens\n",
      "    return [t for t in tokens if len(t) and not t.isspace()]\n",
      "\n",
      "\n",
      "def parse_list(tokens):\n",
      "    \"\"\"Parse a List\n",
      "    \n",
      "    Consume a (operator operand1 operand2 operand3 ...) expression.  Syntatically\n",
      "    the opening '(' is always followed by an operator, and then a list of at least 1 or\n",
      "    up to many operands.  This function consumes the opening '(' and the operator and\n",
      "    then calls another function to get the list of operands.  When the operands are\n",
      "    gathered, this funciton expects and consumes the closing ')'.  The resulting \n",
      "    parse is put into a list, and the list and any remaining tokens are returned by\n",
      "    this function.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tokens : list\n",
      "        A python list of valid tokens.  This function expects the first token to be the '('\n",
      "        keyword, and the second token will be an operator.\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    ast : list (of python lists)\n",
      "        Return the resulting abstract syntax tree as a list of lists\n",
      "    tokens : list of strings\n",
      "        Also any remaining tokens after parsing the current list and operands are returned\n",
      "        (to be used for further parsing).\n",
      "    \"\"\"\n",
      "    # expect ( always as first token for this function\n",
      "    first = tokens.pop(0) # first and rest now in tokens\n",
      "    if first != '(':\n",
      "        print \"(parse_list) Error: expected '(' token, found <%s>\" % first\n",
      "        sys.exit(0)\n",
      "    \n",
      "    # consume the operator and all operands\n",
      "    operator = tokens.pop(0) # operator always after opening ( syntatically\n",
      "    operands, tokens = parse_operands(tokens)\n",
      "    ast = [operator]\n",
      "    ast.extend(operands)\n",
      "    \n",
      "    # consume the matching )\n",
      "    first = tokens.pop(0) \n",
      "    if first != ')':\n",
      "        print \"(parse_list) Error: expected ')' token, found <%s>\" % first\n",
      "        \n",
      "    return ast, tokens\n",
      "\n",
      "\n",
      "def is_float(s):\n",
      "    \"\"\"Function to test whether given string can be interpreted as a valid floating\n",
      "    point literal value or not.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    s : string\n",
      "        A python string holding a symbol to test\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    result : boolean\n",
      "        True if the string is a valid floating point value, False otherwise\n",
      "    \"\"\"\n",
      "    try:\n",
      "        float(s)\n",
      "        return True\n",
      "    except ValueError:\n",
      "        return False\n",
      "\n",
      "\n",
      "def is_int(s):\n",
      "    \"\"\"Function to test whether given string can be interpreted as a valid integer\n",
      "    literal value or not.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    s : string\n",
      "        A python string holding a symbol to test\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    result : boolean\n",
      "        True if the string is a valid integer, False otherwise\n",
      "    \"\"\"\n",
      "    try:\n",
      "        int(s)\n",
      "        return True\n",
      "    except ValueError:\n",
      "        return False\n",
      "\n",
      "\n",
      "def parse_operands(tokens):\n",
      "    \"\"\"Consume a sequence of operands\n",
      "    \n",
      "    We consume all of the operands of a Lisp like stream of tokens.  We keep going till\n",
      "    there are no tokens left to consume, or we reach a closing ')' expression.  In addition\n",
      "    this function will recursively call parse_list() if it sees an opening '(', in order to\n",
      "    get the sub AST parsed expression.  Syntatically a sub AST is simply an additional \n",
      "    operand of the current list of operands, so if one is found it is just appended to the\n",
      "    list, and we then continue on trying to parse other operands.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tokens : list\n",
      "        A python list of valid tokens.  \n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    ast : list\n",
      "        A partial list of the parsed abstract syntax tree, basically all of the operands we\n",
      "        could consume from the stream of tokens we were given (including any parsed\n",
      "        subexpressions).\n",
      "    tokens : list\n",
      "        A list of token strings.  The remaining tokens in the parse stream (needed for\n",
      "        further processing).\n",
      "    \"\"\"\n",
      "    operands = []\n",
      "    done = False\n",
      "    while len(tokens) > 0:\n",
      "        # peek at next token, and if not an operand then stop\n",
      "        if tokens[0] == ')':\n",
      "            break\n",
      "\n",
      "        # if next token is a (, need to get subexpression\n",
      "        if tokens[0] == '(':\n",
      "            subast, tokens = parse_list(tokens)\n",
      "            operands.append(subast)\n",
      "            continue\n",
      "            \n",
      "        # otherwise token must be some sort of an operand\n",
      "        operand = tokens.pop(0) # consume the token and parse it\n",
      "        \n",
      "        # assume we have an operand, try and cast numeric operands, or\n",
      "        # if not numeric simply leave and treat as a string value\n",
      "        if is_int(operand):\n",
      "            operands.append(int(operand))\n",
      "        elif is_float(operand):\n",
      "            operands.append(float(operand))\n",
      "        else: # treat as a string literal\n",
      "            operands.append(operand)\n",
      "    \n",
      "    return operands, tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# unit tests of the simple Python Lisp Parser\n",
      "import unittest\n",
      "\n",
      "class TestPythonLispParser(unittest.TestCase):\n",
      "    \n",
      "    def test_tokenizer_extra_space(self):\n",
      "        self.assertEqual(tokenize(\" (  + apples oranges )  \"), \n",
      "                         ['(', '+', 'apples', 'oranges', ')'])\n",
      "\n",
      "    def test_tokenizer_compact(self):\n",
      "        self.assertEqual(tokenize(\"((+ 1 (2 (3 4))))\"), \n",
      "                         ['(', '(', '+', '1', '(', '2', '(', '3', '4', ')', ')', ')', ')'])\n",
      "\n",
      "    def test_tokenizer_bigger(self):\n",
      "        self.assertEqual(tokenize(\"(first (list 1 (+ 2 3) 9))\"), \n",
      "                         ['(', 'first', '(', 'list', '1', '(', '+', '2', '3', ')', '9', ')', ')'])\n",
      "\n",
      "    def test_is_int_string(self):\n",
      "        self.assertFalse(is_int('hello'))\n",
      "\n",
      "    def test_is_int_valid(self):\n",
      "        self.assertTrue(is_int('42'))\n",
      "\n",
      "    def test_is_int_given_a_float(self):\n",
      "        self.assertFalse(is_int('38.29'))\n",
      "\n",
      "    def test_is_float_string(self):\n",
      "        self.assertFalse(is_float('goodbye'))\n",
      "\n",
      "    def test_is_float_valid(self):\n",
      "        self.assertTrue(is_float('18.76'))\n",
      "        \n",
      "suite = unittest.TestLoader().loadTestsFromTestCase(TestPythonLispParser)\n",
      "_ = unittest.TextTestRunner(verbosity=1, stream=sys.stderr).run(suite)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "----------------------------------------------------------------------\n",
        "Ran 8 tests in 0.007s\n",
        "\n",
        "OK\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}